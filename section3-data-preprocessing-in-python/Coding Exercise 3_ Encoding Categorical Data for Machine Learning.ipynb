{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCByuwvstDbL"
   },
   "source": [
    "# Coding Exercise 3: Encoding Categorical Data for Machine Learning\n",
    "\n",
    "1: Import required libraries - Pandas, Numpy, and required classes for this task - ColumnTransformer, OneHotEncoder, LabelEncoder.\n",
    "\n",
    "2: Start by loading the Titanic dataset into a pandas data frame. This can be done using the pd.read_csv function. The dataset's name is 'titanic.csv'.\n",
    "\n",
    "3: Identify the categorical features in your dataset that need to be encoded. You can store these feature names in a list for easy access later.\n",
    "\n",
    "4: To apply OneHotEncoding to these categorical features, create an instance of the ColumnTransformer class. Make sure to pass the OneHotEncoder() as an argument along with the list of categorical features.\n",
    "\n",
    "5: Use the fit_transform method on the instance of ColumnTransformer to apply the OneHotEncoding.\n",
    "\n",
    "6: The output of the fit_transform method should be converted into a NumPy array for further use.\n",
    "\n",
    "7: The 'Survived' column in your dataset is the dependent variable. This is a binary categorical variable that should be encoded using LabelEncoder.\n",
    "\n",
    "8: Print the updated matrix of features and the dependent variable vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1731791499836,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "nEWcEKVgtCN5",
    "outputId": "0c7677f6-68fc-4e5b-a36c-17c55d5b7d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('datasets/iris.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Split features and target\n",
    "X = df.iloc[:, [0] + list(range(2, df.shape[1]))]\n",
    "y = df.iloc[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731791414513,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "7gDExwfZwSOJ",
    "outputId": "1936527f-a10b-4e5b-d46a-561e33632394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                               Name  \\\n",
      "0              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "1              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "2              7       1                            McCarthy, Mr. Timothy J   \n",
      "3             11       3                    Sandstrom, Miss. Marguerite Rut   \n",
      "4             12       1                           Bonnell, Miss. Elizabeth   \n",
      "..           ...     ...                                                ...   \n",
      "178          872       1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
      "179          873       1                           Carlsson, Mr. Frans Olof   \n",
      "180          880       1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   \n",
      "181          888       1                       Graham, Miss. Margaret Edith   \n",
      "182          890       1                              Behr, Mr. Karl Howell   \n",
      "\n",
      "        Sex   Age  SibSp  Parch    Ticket     Fare        Cabin Embarked  \n",
      "0    female  38.0      1      0  PC 17599  71.2833          C85        C  \n",
      "1    female  35.0      1      0    113803  53.1000         C123        S  \n",
      "2      male  54.0      0      0     17463  51.8625          E46        S  \n",
      "3    female   4.0      1      1   PP 9549  16.7000           G6        S  \n",
      "4    female  58.0      0      0    113783  26.5500         C103        S  \n",
      "..      ...   ...    ...    ...       ...      ...          ...      ...  \n",
      "178  female  47.0      1      1     11751  52.5542          D35        S  \n",
      "179    male  33.0      0      0       695   5.0000  B51 B53 B55        S  \n",
      "180  female  56.0      0      1     11767  83.1583          C50        C  \n",
      "181  female  19.0      0      0    112053  30.0000          B42        S  \n",
      "182    male  26.0      0      0    111369  30.0000         C148        C  \n",
      "\n",
      "[183 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731791414513,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "sd1-4ok_x2FR",
    "outputId": "93eabafe-b3e9-4689-8f7b-200fc0597c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "178    1\n",
      "179    0\n",
      "180    1\n",
      "181    1\n",
      "182    1\n",
      "Name: Survived, Length: 183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731791414513,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "6tnQXPugwQwR",
    "outputId": "546ffeca-a74d-40ab-e056-97adf894aa13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731791414513,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "KjupLxBjyOJi",
    "outputId": "f65ec9b4-1ca7-42f8-856b-4418e03410a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_7dxNwdyeYK"
   },
   "source": [
    "### Encoding Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1731791507676,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "Sb3q2AeZxKp4"
   },
   "outputs": [],
   "source": [
    "# Identify the categorical data\n",
    "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
    "\n",
    "# Implement an instance of the ColumnTransformer class\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_features)], remainder='passthrough')\n",
    "\n",
    "# Apply the fit_transform method on the instance of ColumnTransformer\n",
    "X = ct.fit_transform(df)\n",
    "\n",
    "# Convert the output into a NumPy array\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKRJ6lSmyhok"
   },
   "source": [
    "### Encoding Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1731791510667,
     "user": {
      "displayName": "Amara Chaw",
      "userId": "15442814865005417977"
     },
     "user_tz": 300
    },
    "id": "BnW_W0C9xfwH",
    "outputId": "225a6e23-7ca1-4b0e-9456-cbb8aaa18143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Use LabelEncoder to encode binary categorical data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Print the updated matrix of features and the dependent variable vector\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSwkz4Voa+gOqEJZfk8+l+",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
